{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-kogvXnGCAK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "try:\n",
        "    dataset = pd.read_csv('/content/spam (6).csv', sep='\\t', names=['label', 'message'], encoding='latin1')\n",
        "    print(dataset.head())\n",
        "except UnicodeDecodeError:\n",
        "    try:\n",
        "        dataset = pd.read_csv('/content/spam (6).csv', sep='\\t', names=['label', 'message'], encoding='ISO-8859-1')\n",
        "        print(dataset.head())\n",
        "    except UnicodeDecodeError:\n",
        "        dataset = pd.read_csv('/content/spam (6).csv', sep='\\t', names=['label', 'message'], encoding='cp1252')\n",
        "        print(dataset.head())"
      ],
      "metadata": {
        "id": "OpHK6HStJJIp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5e20c16-929f-43b7-98f5-92a5fb4308cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               label  message\n",
            "0                                           v1,v2,,,      NaN\n",
            "1  ham,\"Go until jurong point, crazy.. Available ...      NaN\n",
            "2               ham,Ok lar... Joking wif u oni...,,,      NaN\n",
            "3  spam,Free entry in 2 a wkly comp to win FA Cup...      NaN\n",
            "4  ham,U dun say so early hor... U c already then...      NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to check null\n",
        "dataset.info()\n"
      ],
      "metadata": {
        "id": "YqxUCOmvL2ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 method\n",
        "dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "ivO7Ye2vbvJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.describe()"
      ],
      "metadata": {
        "id": "I0CDvNLab-js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#give ham 0 and spam 1\n",
        "dataset['label']=dataset['label'].map({'ham':0, 'spam':1})\n",
        "dataset"
      ],
      "metadata": {
        "id": "JJ6DP_8wcLGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.describe()"
      ],
      "metadata": {
        "id": "nVBTb3qBeshl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize the data\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "ztarIcr6dhwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "p=sns.countplot(x=\"label\",data=dataset)\n",
        "p=plt.title('Countplot for Spam vs Ham as imbalanced dataset')\n",
        "p=plt.xlabel(\"Is the SMS Spam?\")\n",
        "p=plt.ylabel('Count')"
      ],
      "metadata": {
        "id": "z20nzzupe6AG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling imbalanced daatset using oversampling\n",
        "only_spam=dataset[dataset['label']==1]\n",
        "only_spam"
      ],
      "metadata": {
        "id": "EbEDpkz0d-vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"No of spam sms: \",len(only_spam))\n",
        "print(\"No of ham sms: \",len(dataset) - len(only_spam))\n"
      ],
      "metadata": {
        "id": "blIuErt1jyV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count=int((dataset.shape[0] - only_spam.shape[0])/only_spam.shape[0])\n",
        "count"
      ],
      "metadata": {
        "id": "Kg2zqQs3iVZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,count-1):\n",
        "  dataset=pd.concat([dataset, only_spam])\n",
        "dataset.shape"
      ],
      "metadata": {
        "id": "N_TT9t_nhvbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "p=sns.countplot(x=\"label\",data=dataset)\n",
        "p=plt.title('Countplot for Spam vs Ham as balanced dataset')\n",
        "p=plt.xlabel(\"Is the SMS Spam?\")\n",
        "p=plt.ylabel('Count')"
      ],
      "metadata": {
        "id": "GQ1JSCldjpE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating new feature word_count\n",
        "dataset['word_count']=dataset['message'].apply(lambda x: len(x.split()))\n",
        "dataset"
      ],
      "metadata": {
        "id": "p3qxxlFWkAAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "#(1,1)\n",
        "plt.subplot(1,2,1)\n",
        "g=sns.histplot(dataset[dataset[\"label\"]== 0].word_count, kde= True)\n",
        "p=plt.title(\"Distribution of word_count for Ham SMS\")\n",
        "#(1,2)\n",
        "plt.subplot(1,2,2)\n",
        "g=sns.histplot(dataset[dataset[\"label\"]==1].word_count, color=\"red\", kde=True)\n",
        "p=plt.title(\"Distribution of word count for SPAM SMS\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vJh_LQgIkqTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating new feature of containing currency symbols\n",
        "def currency (data):\n",
        "  currency_symbols=['€','$','¥','£ ','₹']\n",
        "  for i in currency_symbols:\n",
        "    if 1 in dataset:\n",
        "      return 1\n",
        "      return 0\n"
      ],
      "metadata": {
        "id": "VfvgQQdmmei3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"contains_currency_symbols\"] = dataset[\"message\"].apply(currency)\n",
        "dataset"
      ],
      "metadata": {
        "id": "ReYPpq7ZocTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['contains_currency_symbols'] = dataset['contains_currency_symbols'].notna()\n"
      ],
      "metadata": {
        "id": "lwUHlgCOKlGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "g = sns.countplot(x='contains_currency_symbols', data=dataset, hue='label')\n",
        "plt.title('Countplot for Containing Currency Symbol')\n",
        "plt.xlabel('Does SMS contain any currency symbol?')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(labels=[\"Ham\", \"Spam\"], loc='upper center')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "k2ZM8zxaKo1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating new feature of containing numbers\n",
        "def number (data):\n",
        "  for i in data:\n",
        "    if ord(i) >=48 and ord(i) <=57:\n",
        "      return 1\n",
        "  return 0\n"
      ],
      "metadata": {
        "id": "1Lr-GAP-K2bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"contains_number\"]= dataset['message'].apply(number)\n",
        "dataset"
      ],
      "metadata": {
        "id": "BoBDLx7tMMVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Countplot for containing numbers\n",
        "plt.figure(figsize=(8,8))\n",
        "g=sns.countplot(x='contains_number', data=dataset, hue= \"label\")\n",
        "p=plt.title('Countplot for Containing Numbers')\n",
        "p=plt.xlabel('Does SMS contains any number?')\n",
        "p=plt.ylabel('count')\n",
        "p=plt.legend(labels=[\"Ham\", \"Spam\"], loc=9)"
      ],
      "metadata": {
        "id": "ZSsnoE_FMqd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Cleaning\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n"
      ],
      "metadata": {
        "id": "YX7wpohjNVPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "corpus = []\n",
        "wnl= WordNetLemmatizer()\n",
        "for sms in list(dataset.message):\n",
        "  message= re.sub(pattern='[^a-zA-Z]', repl=' ', string =sms) # Flitering out special characters and numbers\n",
        "  message= message.lower()\n",
        "  words= message.split() # Tokenizer\n",
        "  filtered_words= [word for word in words if word not in set (stopwords.words('english'))]\n",
        "  lemm_words =[wnl.lemmatize(word) for word in filtered_words]\n",
        "  message=' '.join(lemm_words)\n",
        "  corpus.append(message)"
      ],
      "metadata": {
        "id": "3cuDCjERN6Gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "id": "6QgETbcDVLqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating the Bag of words model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf=TfidfVectorizer(max_features= 500)\n",
        "vectors= tfidf.fit_transform(corpus).toarray()\n",
        "feature_names= tfidf.get_feature_names_out()\n"
      ],
      "metadata": {
        "id": "UGOBJUx8VMxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=pd.DataFrame(vectors, columns= feature_names)\n",
        "y=dataset['label']\n"
      ],
      "metadata": {
        "id": "q1o_fV5QWPsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n"
      ],
      "metadata": {
        "id": "ze7cJQwyYJ6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gThR4S7fZJV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "2Js0zaubZWvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "id": "QZSrk0UIZe_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive Bayes Model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "mnb =MultinomialNB()\n",
        "cv=cross_val_score(mnb, X, y, scoring ='f1', cv=10)\n",
        "print(round(cv.mean(),3))\n",
        "print(round(cv.std(),3))\n"
      ],
      "metadata": {
        "id": "s0Q1koaOZpsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mnb.fit(X_train, y_train)\n",
        "y_pred=mnb.predict(X_test)\n"
      ],
      "metadata": {
        "id": "go7e76Y-ahad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "Dq-yYNR6ap-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm=confusion_matrix(y_test, y_pred)\n",
        "cm\n"
      ],
      "metadata": {
        "id": "3IwIOrmobfUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "axis_labels=['ham', 'spam']\n",
        "g=sns.heatmap(data=cm, xticklabels=axis_labels, yticklabels=axis_labels, annot=True, fmt='g',cbar_kws={'shrink':0.5},cmap=\"Blues\")\n",
        "\n",
        "p=plt.title(\"Confusion Matrix of Multinomial Navie Bayes Model\")\n",
        "p=plt.xlabel('Actual values')\n",
        "p=plt.ylabel(\"Predicted values\")"
      ],
      "metadata": {
        "id": "es4scet9by6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b9ljp6WLcT63"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}